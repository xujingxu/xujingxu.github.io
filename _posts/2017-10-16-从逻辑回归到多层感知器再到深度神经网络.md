---
layout: post
title: "从逻辑回归到多层感知器再到深度神经网络"
date: 2017-10-16 
description: "logistic regression, MLP, DNN"
tag: Deep learning 
---   
  听说过很多次玻尔兹曼机，限制性玻尔兹曼机（RBM），深度玻尔兹曼机（DBM）,深度置信网络（DBM）,以及感知器（perceptron），多层感知器（MLP），深度神经网络（DNN）,
在接下来的2篇博客中会详细阐述它们之前的演化及关系，在这篇博客中主要讲述感知器，多层感知器（MLP），深度神经网络（DNN）。

## 程序说明
  
  首先我们通过程序去理解MLP和logistic regression之间的关系，我们同样使用TensorFlow和keras来演示。如果没有安装的话，
  请参考前面的文章[文章链接](http://xujingxu.cn/2017/10/ubuntu14.04%E9%85%8D%E7%BD%AEtensorflow%E5%92%8Ckeras/)

	$ import numpy as np
	$ from sklearn.datasets import make_circles
	$ from keras.layers import Input, Dense
	$ from keras.models import Sequential
	$ X, y = make_circles(n_samples=5000, factor=.3, noise=.05)
	$ X_train = X[:4000]
	$ y_train = y[:4000]
	$ X_val = X[4000:]
	$ y_val = y[4000:]
	$ num_variables = X.shape[1]
	
	$ logreg = Sequential()
	$ logreg.add(Dense(output_dim=1, input_dim=num_variables, activation='sigmoid'))
	
	$ logreg.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
	$ logreg.fit(X_train, y_train,validation_data=[X_val,y_val],verbose=0)
	$ val_score = logreg.evaluate(X_val,y_val,verbose=0)
  
   上面是一个logistic regression实现分类的例子。logistic回归是一种概率的线性分类器。它是参数化的权重矩阵W和偏置向量B分类是将输入向量到一套超平面，每个点对应一个类。从输入到超平面的距离反映了输入是对应类的成员的概率。
   
 	$ num_hidden = 128
 	$ mlp = Sequential()
	$ mlp.add(Dense(output_dim=num_hidden, input_dim=num_variables, activation='relu'))
	% mlp.add(Dense(output_dim=num_hidden, input_dim=numhidden, activation='relu'))
	% mlp.add(Dense(output_dim=1, activation='sigmoid'))
	% mlp.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
	% mlp.fit(X_train, y_train,validation_data=[X_val,y_val],nb_epoch=10,verbose=1)
	
  这是一个使用多层感知器实现分类的例子，MLP可以被看作是一个logistic回归分类器，其中输入首先使用非线性变换φ进行转换。这个转换将输入数据投射到一个空间中，它变成线性可分的空间。这个中间层称为隐藏层。单隐层足以使MLP的通用逼近。然而，我们稍后会看到，使用许多这样的隐藏层有巨大的好处，也就是深层学习的前提。
  
  如果我们加入足够的隐藏层，这样就可以看成深度神经网络（DNN）了。
  
## 概念理解

### 感知器（Perceptron）

  感知器（Perceptron），是神经网络中的一个概念，在1950s由Frank Rosenblatt第一次引入，是神经网络和支持向量机的基础。.单层感知器（Single Layer Perceptron）是最简单的神经网络。它包含输入层和输出层，而输入层和输出层是直接相连的.
  
  感知器（Perceptron） 是一种用于线性可分数据集的二元分类器算法，这种算法的局限性很大。感知器、logistic与SVM,三者都是线性分类器，而logistic和svm是由感知器发展改善而来的，区别在于三者的损失函数不同：
  
  1.感知器：感知器的损失函数为误分类点的函数间隔之和，函数间隔可以理解为样本与分类超平面的距离。误分类点距离分类超平面越远，则损失函数值越大。只有误分类的点会影响损失函数的值。 
  
	$ L=−y(wTx+b)
	
  2.logistic regression: 感知器模型简单直观，但问题在于这个模型不够光滑，比如如果对于一个新的样本点我们计算出ω^T x+b=0.001，只比0大了一点点就会被分为正样本。同时这个点在0处有一个阶跃，导致这一点不连续，在数学上处理起来不方便。 
  
  那有没有办法让 ωTx+b 到y的映射变得更加光滑呢，人们发现logistic函数有着这样的特性，输入范围是−∞→+∞，而值域光滑地分布于0和1之间。于是就有了logistic回归，正样本点分类的超平面距离越远，ωTx+b 越大，而logistic函数值则越接近于1。负样本点分类的超平面距离越远，ωTx+b 越小，而logistic函数值则越接近于0。
  
  Logistic回归的损失函数为logistic损失函数，当分类错误时，函数间隔越大，则损失函数值越大。当分类正确时，样本点距离超平面越远，则损失函数值越小。所有的样本点分布情况都会影响损失函数最后的值。
  
	$ log(1+exp(−y(wTx+b)))
	
  3.svm: 增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。SVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。两者的根本目的都是一样的。此外，根据需要，两个方法都可以增加不同的正则化项，如l1,l2等等。所以在很多实验中，两种算法的结果是很接近的。

### 多层感知器(MLP)

  多层感知器（Multi-Layer Perceptrons），包含多层计算。相对于单层感知器，输出端从一个变到了多个；输入端和输出端之间也不光只有一层，现在又两层:输出层和隐藏层。训练MLP多采用反向传播学习模型(BP算法)，计算输出节点的总误差，并将这些误差用反向传播算法传播回网络，以计算梯度。接下来，使用类似梯度下降之类的算法来调整网络中的所有权重，目的是减少输出层的误差。
  
  
### 深度神经网络（DNN）

  多层感知机给我们带来的启示是，神经网络的层数直接决定了它对现实的刻画能力——利用每层更少的神经元拟合更加复杂的函数.
  
  即便大牛们早就预料到神经网络需要变得更深，但随着神经网络层数的加深，优化函数越来越容易陷入局部最优解，并且这个“陷阱”越来越偏离真正的全局最优。利用有限数据训练的深层网络，性能还不如较浅层网络。同时，另一个不可忽略的问题是随着网络层数增加，“梯度消失”现象更加严重。具体来说，我们常常使用sigmoid作为神经元的输入输出函数。对于幅度为1的信号，在BP反向传播梯度时，每传递一层，梯度衰减为原来的0.25。层数一多，梯度指数衰减后低层基本上接受不到有效的训练信号。
  
  2006年，Hinton利用预训练方法缓解了局部最优解问题，将隐含层推动到了7层，神经网络真正意义上有了“深度”，由此揭开了深度学习的热潮。这里的“深度”并没有固定的定义——在语音识别中4层网络就能够被认为是“较深的”，而在图像识别中20层以上的网络屡见不鲜。为了克服梯度消失，ReLU、maxout等传输函数代替了sigmoid，形成了如今DNN的基本形式。单从结构上来说，全连接的DNN和多层感知机是没有任何区别的。
  
#### 深度神经网络的局限和发展
  
  1.全连接DNN的结构里下层神经元和所有上层神经元都能够形成连接，带来的潜在问题是参数数量的膨胀。假设输入的是一幅像素为1000x1000的图像，隐含层有1M个节点，光这一层就有10^12个权重需要训练，这不仅容易过拟合，而且极容易陷入局部最优。另外，图像中有固有的局部模式（比如轮廓、边界，人的眼睛、鼻子、嘴等）可以利用，显然应该将图像处理中的概念和神经网络技术相结合。此时我们可以祭出题主所说的卷积神经网络CNN。对于CNN来说，并不是所有上下层神经元都能直接相连，而是通过“卷积核”作为中介。同一个卷积核在所有图像内是共享的，图像通过卷积操作后仍然保留原先的位置关系。CNN中还有max-pooling等操作进一步提高鲁棒性。
  
  2.全连接的DNN还存在着另一个问题——无法对时间序列上的变化进行建模。然而，样本出现的时间顺序对于自然语言处理、语音识别、手写体识别等应用非常重要。对了适应这种需求，就出现了题主所说的另一种神经网络结构——循环神经网络RNN。在RNN中，神经元的输出可以在下一个时间戳直接作用到自身，即第i层神经元在m时刻的输入，除了（i-1）层神经元在该时刻的输出外，还包括其自身在（m-1）时刻的输出！RNN可以看成一个在时间上传递的神经网络，它的深度是时间的长度！正如我们上面所说，“梯度消失”现象又要出现了，只不过这次发生在时间轴上。对于t时刻来说，它产生的梯度在时间轴上向历史传播几层之后就消失了，根本就无法影响太遥远的过去。为了解决时间上的梯度消失，机器学习领域发展出了长短时记忆单元LSTM，通过门的开关实现时间上记忆功能，并防止梯度消失。
  

  
  
  
  

  
	
	
  

	
	
  
	
  
  
