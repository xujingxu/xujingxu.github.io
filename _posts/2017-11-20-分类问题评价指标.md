---
layout: post
title: "分类问题评价指标"
date: 2017-11-20 
description: "分类问题的评价指标和一些概念"
tag: classification
---

之前一直用CNN做分类问题，包括男女肌肉图像分类以及可视化和乳腺癌良恶性的诊断，归根到底是一个二分类问题。这篇博文将对一些分类问题中基本概念和评价指标做
一个简单梳理。

### 几个常用的术语

现在假设我们的分类目标只有2类，正例（positive）和负例（negtive）

* True positives(TP):  被正确地划分为正例的个数，即实际为正例且被分类器划分为正例的实例数（样本数）；
* False positives(FP): 被错误地划分为正例的个数，即实际为负例但被分类器划分为正例的实例数；
* False negatives(FN): 被错误地划分为负例的个数，即实际为正例但被分类器划分为负例的实例数；
* True negatives(TN): 被正确地划分为负例的个数，即实际为负例且被分类器划分为负例的实例数.
* P=正样本个数，N=负样本个数.

### 评价指标

<1> 正确率(accuracy)

正确率是我们最常见的评价指标
$ accuracy = (TP+TN)/(P+N).

<2> 错误率(error rate)

错误率则与正确率相反，描述被分类器错分的比例，error rate = (FP+FN)/(P+N).

<3> 灵敏度(sensitive)

sensitive = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力.

<4> 特异度(specificity)

specificity = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力.

<5> 精度(precision)

精度是精确性的度量，表示被分为正例的示例中实际为正例的比例，precision=TP/（TP+FP）.

<6> 召回率(recall)也称为 True Positive Rate:

recall=TP/(TP+FN)=TP/P, 反映了被正确判定的正例占总的正例的比重.

<7> Fn-score

Fn_score=(n*n+1)*recall*precision/(n*n*precision+recall).

F1_score=2*recall*precision/(recall+precision).

<8> ROC(Receiver Operating Characteristic), AUC(Area Under roc Curve)

ROC空间将伪阳性率（FPR）定义为 X 轴，真阳性率（TPR）定义为 Y 轴。这两个值由上面四个值计算得到，TPR=TP/(TP+FN)，FPR=FP/(FP+TN).
现在我们需要一个独立于阈值的评价指标来评价分类器的效果，也就是遍历所有的阈值,得到ROC曲线.

AUC值为ROC曲线所覆盖的区域面积,显然,AUC越大,分类器分类效果越好.

<9> top-n error(多分类问题，主要用于ImageNet)

top1就是你预测的label取最后概率向量里面最大的那一个作为预测结果，你的预测结果中概率最大的那个类必须是正确类别才算预测正确.
而top5就是最后概率向量最大的前五名中出现了正确概率即为预测正确.

























