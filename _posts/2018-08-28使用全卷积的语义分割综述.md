---
layout: post
title: "使用全卷积的语义分割综述"
date: 2018-08-28 
description: "使用全卷积的语义分割综述"
tag: Deep learning 
---  

图像的语义分割是为输入图像中的每个像素分配语义类，以便获得像素密集分类。虽然语义分割/场景解析自2007年以来一直是计算机视觉社区的一部分，
但与计算机视觉领域的其他领域非常相似，当2014年Long等人首次使用完全卷积神经网络时，取得了重大突破,实现自然图像的端到端分割。

所提出的FCN结构相对于Pascal VOC 2012数据集上的62.2%平均的IU实现了20%的提升。

完全卷积网络（FCN）用于自然图像的语义分割，用于多模态医学图像分析和多光谱卫星图像分割。
与像AlexNet，VGG，ResNet等深度分类网络非常相似，还有各种各样的深层体系结构执行语义分割。

本文总结FCN, SegNet, U-Net, FC-Densenet&Link-Net, RefineNet, PSPNet, Mask-RCNN和一些半监督的方法DecoupleNet和GAN-SS,并且提供PyTorch参考。

### 网络结构

一般语义分割架构可以广泛地被认为是编码器网络，其后是解码器网络。编码器通常是为预训练的分类网络等VGG/Resnet,随后由解码器网络。
所述解码器网络/机制主要是其中这些结构不同。解码器的任务是将由编码器学习的判别特征（较低分辨率）语义地投影到像素空间（较高分辨率）上以获得密集分类。

与深度网络的最终结果（即类存在概率）是唯一重要的分类不同，语义分割不仅需要在像素级别进行区分，而且还需要一种机制来将在编码器的不同阶段学习的判别特征投影到像素空间。
不同的体系结构采用不同的机制（跳过连接，金字塔池等）作为解码机制的一部分。

####1. 全卷积神经网络（FCN） 

CVPR 2015  <a target="_blank" href="https://arxiv.org/abs/1411.4038/"> arXiv </a>

我们将常用的分类网络（AlexNet，VGG网和GoogLeNet）调整为完全卷积网络，并通过微调到分割任务来转移他们学习的表示。
然后，我们定义了一种新颖的架构，它将来自深层粗糙层的语义信息与来自浅层精细层的外观信息相结合，以生成准确而详细的分割。
我们的完全卷积网络实现了PASCAL VOC的最先进分割（2012年平均IU的相对改善率为20％，平均IU为62.2％）。

这种网络的一些关键特征是：

1.特征从编码器中的不同阶段合并，其在语义信息的粗糙度方面变化。

2.学习的低分辨率语义特征图的上采样是使用用全向插值滤波器初始化的反卷积来完成的。

3.从 VGG16，Alexnet等分类器网络进行知识转移的优秀示例，用于执行语义分割

全连接的分类网络层（fc6，fc7）VGG16转换为完全卷积层，它产生低分辨率的类存在热图，然后使用全面初始化的反卷积进行上采样，
并在每个上采样阶段进一步采样通过融合（简单添加）特征来改进，这些特征来自VGG 16（conv4和conv3）中较低层的较粗但较高分辨率的特征映射。

在传统的分类CNN中，池化用于增加视野并且同时降低特征图分辨率。虽然这最适合分类，但最终目标是找到特定类的存在，而对象的空间位置不相关。
因此，在每个卷积块之后引入池化，以使后续块从池化特征中提取更抽象的特征。

另一方面，随着空间信息的丢失，任何类型的操作 - 汇集或跨步卷积都导致结果恶化。
FCN从不同粗糙度特征（conv3，conv4和fc7）来改进添加不同阶段的不同分辨率的空间信息。
语义分割体系结构的其他重要方面是用于对低分辨率分割图进行特征上采样以使用学习的反卷积增大输入图像分辨率的机制，
或者使用扩张的卷积来增大特征图尺寸，提升分辨率。

####2. SegNet

2015 SegNet：用于图像分割的深度卷积编码器 - 解码器架构  <a target="_blank" href="https://arxiv.org/abs/1511.00561/"> arXiv </a>

SegNet的新颖之处在于解码器对其较低分辨率输入特征图进行上采样的方式。具体地，解码器使用在相应编码器的最大池化步骤中计算的池化索引来执行非线性上采样。
这消除了学习上采样的需要。上采样的特征图是稀疏的，然后与可训练的滤波器卷积以产生密集的特征图。
我们将我们提出的架构与广泛采用的FCN以及众所周知的DeepLab-LargeFOV，DeconvNet架构进行比较。
这种比较揭示了实现良好分割性能所涉及的内存与准确度之间的权衡。

这种网络的一些关键特征是：

1.SegNet使用unpooling对解码器中的特征映射进行上采样，以便在分段中使用并保持高频细节不变。

2.该编码器不使用全连接的层，因此是轻量级网络较小的参数。

存储编码器中每个最大合并层的索引，然后用于通过使用那些存储的索引解开它来解码解码器中的相应特征图。
虽然这有助于保持高频信息的完整性，但是当从低分辨率特征映射中解放时，它也会错过相邻信息。

####3. U-Net

MICCAI 2015 U-Net：用于生物医学图像分割的卷积网络  <a target="_blank" href="https://arxiv.org/abs/1505.04597/"> arXiv </a>

该体系结构包括捕获上下文的跳跃路径和实现精确定位的对称扩展路径。我们表明，这种网络可以从非常少的图像端到端地进行训练，
并且优于ISBI挑战中的先前最佳方法（滑动窗口卷积网络），用于电子显微镜堆叠中的神经元结构的分割。
使用在透射光显微镜图像（相位对比和DIC）上训练的相同网络，
我们在这些类别中大幅度赢得了2015年ISBI细胞追踪挑战。而且，网络很快。在最近的GPU上，512x512图像的分割不到一秒钟

1.U-Net简单地将编码器特征映射连接到每个阶段的解码器的上采样特征映射，以形成梯形结构。该网络非常类似于Ladder Networks类型的架构。

2.通过其跳过concatenation连接的架构允许每个阶段的解码器学习在编码器中汇集时丢失的相关特征。

U-Net在EM Stacks数据集上实现了最先进的结果，该数据集仅包含30个密集注释的医学图像和其他医学图像数据集，后来扩展到3D版3D-U-Net。
<a target="_blank" href="https://arxiv.org/abs/1606.06650/"> arXiv </a>
虽然U-Net最初发布用于生物医学分割，网络的实用性及其从非常少的数据中学习的能力，但它已经在卫星图像分割的其他几个领域中得到应用，
并且也成为许多kaggle获胜解决方案的一部分。医学图像分割竞赛。

####4. Fully Convolutional DenseNet

2016 The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation
<a target="_blank" href="https://arxiv.org/abs/1611.09326/"> arXiv </a>

在本文中，我们扩展了DenseNets来处理语义分割问题。我们在城市场景基准数据集（如CamVid和Gatech）上实现了最先进的结果，
无需任何进一步的后处理模块或预训练。此外，由于模型的智能构造，我们的方法比目前公布的这些数据集的最佳条目具有更少的参数。

完全卷积DenseNet使用DenseNet作为其基本编码器，并且以类似于U-Net的方式连接每个梯级的编码器和解码器的功能。

####5. E-Net和Link-Net

2016 ENet：用于实时语义分割的深度神经网络体系结构  <a target="_blank" href="https://arxiv.org/abs/1606.02147/"> arXiv </a>

2017  Feature Forwarding: Exploiting Encoder Representations for Efficient Semantic Segmentation
<a target="_blank" href="https://codeac29.github.io/projects/linknet/"> 博客 </a>

在本文中，我们提出了一种新的深度神经网络架构，名为ENet（高效神经网络），专门为需要低延迟操作的任务而创建。
ENet的速度提高了18倍，FLOP要求减少了75倍，参数减少了79倍，并且为现有型号提供了类似或更好的精度。
我们已经在CamVid，Cityscapes和SUN数据集上对其进行了测试，并报告了与现有最先进方法的比较，以及网络准确性和处理时间之间的权衡。
算法思路类似 U-Net，引入了 residual blocks

LinkNet可以分别以2 fps和19 fps的速率处理TX1和Titan X上分辨率为1280x720的输入图像

####5. Mask R-CNN

2017 ICCV best paper  <a target="_blank" href="https://arxiv.org/abs/1703.06870/"> arXiv </a>

该方法称为Mask R-CNN，通过添加用于预测与现有分支并行的对象掩码的分支来扩展更快的R-CNN以用于边界框识别。Mask R-CNN易于训练，
只需很少的开销即可以更快的速度增加R-CNN，运行速度为5 fps。此外，Mask R-CNN很容易推广到其他任务，例如，允许我们在同一框架中估计人体姿势。
我们在COCO挑战套件的所有三个轨道中展示了最佳结果，包括实例分割，边界框对象检测和人员关键点检测。
没有技巧，Mask R-CNN在每项任务中都优于所有现有的单一模型条目，包括COCO 2016挑战赛获胜者。

Mask R-CNN架构相当简单，它是流行的Faster R-CNN架构的扩展，具有执行语义分割所需的必要更改。

该架构的一些主要功能包括：

1.更快的R-CNN具有辅助分支以执行语义分割。

2.用于参与每个实例的RoIPool操作已被修改为RoIAlign，这避免了用于特征提取的空间量化，因为保持空间特征以尽可能高的分辨率保持完整对于语义分割是重要的。

3.Mask R-CNN与特征金字塔网络（以类似于PSPNet的方式执行特征的金字塔池化）相结合，在MS COCO数据集上实现了最先进的结果。

####6. PSPNet

CVPR 2017 PSPNet: 金字塔场景解析网络 <a target="_blank" href="https://arxiv.org/abs/1612.01105/"> arXiv </a>

在本文中，我们通过我们的金字塔池模块和提出的金字塔场景解析网络（PSPNet），通过基于不同区域的上下文聚合来利用全局上下文信息的能力。
我们的全局先验表示有效地在场景解析任务中产生高质量的结果，而PSPNet为像素级预测提供了优越的框架。所提出的方法在各种数据集上实现了最先进的性能。
它首先出现在ImageNet场景解析挑战2016，PASCAL VOC 2012基准测试和Cityscapes基准测试中。

该架构的一些主要功能包括：

1.PSPNet 通过合并膨胀卷积来修改基本ResNet架构，并且在初始池之后，在1/4th整个编码器网络中以相同的分辨率（原始图像输入）处理特征，直到它到达空间池模块。

2.在ResNet的中间层中引起辅助损失，以优化学习整体学习。

3.空间金字塔池在修改后的ResNet编码器的顶部汇集全局上下文

####7. RefineNet

CVPR 2017 RefineNet：用于高分辨率语义分割的多路径细化网络 <a target="_blank" href="https://arxiv.org/abs/1611.06612/"> arXiv </a>

在这里，我们介绍RefineNet，这是一个通用的多路径优化网络，它明确利用沿着采样过程提供的所有信息，以使用远程残留连接实现高分辨率预测。
通过这种方式，可以使用早期卷积中的细粒度特征直接细化捕获高级语义特征的更深层。RefineNet的各个组件采用身份映射思维模式后的剩余连接，
从而实现有效的端到端训练。

RefineNet以与PSPNet（使用计算上昂贵的扩张卷积）非常不同的方式解决了传统网络中空间分辨率降低的问题。所提出的架构迭代地使用针对多个分辨率范围的特殊RefineNet块来增加分辨率，并最终生成高分辨率分割图。

该架构的一些功能包括：

1. 使用多种分辨率的输入，融合提取的特征并将它们传递到下一阶段。

2.介绍链式残留池，它能够从大图像区域捕获背景上下文。它通过有效地汇集具有多个窗口大小的功能并将它们与剩余连接和可学习的权重融合在一起来实现

3.所有功能融合都使用sum（ResNet风格）完成，以实现端到端的培训。

4.使用vanilla ResNet样式残留层，无需昂贵的扩张卷积

####8. G-FRNet

CVPR 2017	G-FRNet：用于密集图像标记的门控反馈细化网络	 <a target="_blank" href="http://www.cs.umanitoba.ca/~ywang/papers/cvpr17.pdf/"> arXiv </a>

在本文中，我们提出了门控反馈精化网络（G-FRNet），这是一种用于密集标记任务的端到端深度学习框架，可解决现有方法的这种局限性。
最初，GFRNet进行粗略预测，然后通过在细化阶段有效地整合本地和全局上下文信息，逐步细化细节。我们引入了控制传递信息的门单元，以滤除模糊性。

上述大多数体系结构依赖于从编码器通过简单的功能使用到解码器concatenation，unpooling或简单sum。
然而，从编码器中的较高分辨率（较少辨别）层流到解码器中的对应上采样特征图的信息可能或可能不具有用于分割的效用。
使用门控细化反馈单元在每个阶段将来自编码器的信息流门控到解码器可以帮助解码器解决模糊并形成更相关的gated空间上下文。



####9. DecoupledNet(半监督语义分割)

NIPS 2015	解耦深度神经网络用于半监督语义分割  <a target="_blank" href="https://arxiv.org/abs/1506.04924/"> arXiv </a>

与将语义分割作为基于区域的分类的单个任务的现有方法相反，我们的算法将分类和分割分离，并为每个任务学习单独的网络。
在该体系结构中，通过分类网络识别与图像相关联的标签，随后对分割网络中的每个识别的标签执行二进制分割。通过利用从桥接层获得的类特定激活图，
它有助于有效地减少用于分割的搜索空间。

这可能是第一个使用完全卷积网络进行语义分割的半监督方法。

这种方法的一些特征是：

1.解耦分类和分段任务，从而使预先训练的分类网络能够被插入和播放。

2.分类和分段网络之间的桥接层生成类静默特征映射（用于类k），然后由分段网络用于生成二进制分段映射（用于类k）

3.然而，该方法需要k遍传到图像中的k个分段。

####10. 基于GAN的方法

2017年	基于生成对抗网络的半弱监督语义分割	  <a target="_blank" href="https://arxiv.org/abs/1703.09695/"> arXiv </a>

特别是，我们提出了一个基于生成对抗网络（GAN）的半监督框架，它由一个生成器网络组成，为多类分类器提供额外的训练样例，作为GAN框架中的鉴别器，
分配样本a标记来自K个可能类的y或将其标记为假样本（额外类）。为了确保GAN生成的图像质量更高，从而改进像素分类，我们通过添加弱注释数据来扩展上述框架，
即我们向生成器提供类级别信息。

### 公开数据

Dataset	     Training	  Testing	   #Classes

CamVid	        468	       233	      11

PascalVOC2012	  9963	     1447	      20

NYUDv2	        795	       645	      40

Cityscapes	    2975	     500	      19

Sun-RGBD	      10355	     2860	      37

MS COCO ‘15	    80000	     40000	    80

ADE20K	        20210	     2000	     150
